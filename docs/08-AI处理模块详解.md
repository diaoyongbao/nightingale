# AI 处理模块详解

## 1. 概述

AI 处理模块是 Nightingale 告警流水线（Alert Pipeline）中的一个处理器（Processor），用于对告警事件进行 AI 智能分析和摘要生成。该模块通过调用外部 AI 模型 API（支持 OpenAI 兼容接口）来分析告警事件的详细信息，并生成可读性更强的告警摘要，帮助运维人员快速理解告警的根本原因和影响。

### 1.1 核心功能

- **智能告警摘要**：基于告警事件的上下文信息，使用 AI 模型生成人类可读的告警摘要
- **灵活的模板系统**：支持自定义提示词（Prompt）模板，可根据业务需求定制 AI 分析内容
- **多模型支持**：兼容 OpenAI Chat Completion API 标准的所有模型（如 GPT-4、Claude、Gemini 等）
- **自定义参数**：支持传递模型参数（temperature、max_tokens、top_p 等）
- **无侵入式增强**：生成的摘要自动添加到事件的 annotations 字段，不影响原有告警流程

### 1.2 在告警流水线中的位置

```
告警触发 → 事件生成 → [Pipeline 处理器链]
                         ↓
                    1. relabel      (标签重写)
                    2. event_drop   (事件过滤)
                    3. event_update (事件更新)
                    4. ai_summary   (AI 摘要) ← 本模块
                    5. callback     (回调通知)
                         ↓
                    告警发送
```

---

## 2. 架构设计

### 2.1 模块结构

```
nightingale/alert/pipeline/processor/
├── aisummary/
│   ├── ai_summary.go        # 核心实现
│   └── ai_summary_test.go   # 单元测试
├── common/
│   └── common.go            # 通用初始化逻辑
└── callback/
    └── callback.go          # HTTP 配置基类
```

### 2.2 类图关系

```
┌─────────────────────┐
│  models.Processor  │  (接口)
│  - Init()          │
│  - Process()       │
└──────────┬──────────┘
           │ 实现
           ↓
┌─────────────────────────────┐
│   AISummaryConfig          │
├─────────────────────────────┤
│  + ModelName      string   │  模型名称
│  + APIKey         string   │  API 密钥
│  + PromptTemplate string   │  提示词模板
│  + CustomParams   map      │  自定义参数
│  - HTTPConfig              │  HTTP 配置（继承）
├─────────────────────────────┤
│  + Init()                  │  初始化配置
│  + Process()               │  处理告警事件
│  - initHTTPClient()        │  初始化 HTTP 客户端
│  - prepareEventInfo()      │  准备事件信息
│  - generateAISummary()     │  调用 AI 生成摘要
└─────────────────────────────┘
           │ 包含
           ↓
┌─────────────────────────────┐
│   callback.HTTPConfig      │
├─────────────────────────────┤
│  + URL           string    │
│  + Timeout       int       │
│  + SkipSSLVerify bool      │
│  + Proxy         string    │
│  + Headers       map       │
│  - Client        *http.Client
└─────────────────────────────┘
```

### 2.3 处理器注册机制

所有处理器（包括 AI 模块）都通过 `init()` 函数自动注册到全局注册表中：

```go
// nightingale/models/event_processor.go
var processorRegister = map[string]NewProcessorFn{}

func RegisterProcessor(typ string, p Processor) {
    processorRegister[typ] = p.Init
}
```

注册流程：
1. 包导入时自动执行 `init()` 函数
2. 调用 `models.RegisterProcessor("ai_summary", &AISummaryConfig{})`
3. 将处理器工厂方法存储到全局 map 中
4. 运行时通过 `GetProcessorByType()` 根据类型名称实例化处理器

---

## 3. 核心实现详解

### 3.1 配置结构体

```go
type AISummaryConfig struct {
    callback.HTTPConfig                    // 继承 HTTP 配置
    ModelName      string                 `json:"model_name"`        // AI 模型名称
    APIKey         string                 `json:"api_key"`           // API 密钥
    PromptTemplate string                 `json:"prompt_template"`   // 提示词模板
    CustomParams   map[string]interface{} `json:"custom_params"`     // 自定义参数
}
```

**关键字段说明**：

| 字段 | 类型 | 说明 |
|------|------|------|
| `ModelName` | string | 模型名称（如 `gpt-4`、`gemini-2.0-flash`） |
| `APIKey` | string | API 认证密钥 |
| `PromptTemplate` | string | Go Template 格式的提示词模板 |
| `CustomParams` | map | 额外的模型参数（如 `temperature`、`max_tokens`） |
| `URL` | string | AI API 端点（继承自 HTTPConfig） |
| `Timeout` | int | 请求超时时间（毫秒） |
| `SkipSSLVerify` | bool | 是否跳过 SSL 验证 |
| `Proxy` | string | HTTP 代理地址 |

### 3.2 处理流程

```go
func (c *AISummaryConfig) Process(ctx *ctx.Context, event *models.AlertCurEvent) 
    (*models.AlertCurEvent, string, error) {
    
    // 1. 初始化 HTTP 客户端
    if c.Client == nil {
        c.initHTTPClient()
    }
    
    // 2. 根据模板生成提示词
    eventInfo, err := c.prepareEventInfo(event)
    
    // 3. 调用 AI API 生成摘要
    summary, err := c.generateAISummary(eventInfo)
    
    // 4. 将摘要添加到事件的 annotations 字段
    event.AnnotationsJSON["ai_summary"] = summary
    event.Annotations = json.Marshal(event.AnnotationsJSON)
    
    return event, "", nil
}
```

**处理流程图**：

```
┌─────────────────┐
│  告警事件输入   │
└────────┬────────┘
         │
         ↓
┌────────────────────────┐
│ 1. 初始化 HTTP 客户端 │
│   - 配置超时            │
│   - 配置 SSL 验证       │
│   - 配置代理            │
└────────┬───────────────┘
         │
         ↓
┌────────────────────────┐
│ 2. 生成提示词          │
│   - 解析模板           │
│   - 注入事件数据       │
│   - 执行模板渲染       │
└────────┬───────────────┘
         │
         ↓
┌────────────────────────┐
│ 3. 调用 AI API        │
│   - 构建请求参数       │
│   - 添加认证头         │
│   - 发送 HTTP 请求     │
│   - 解析响应           │
└────────┬───────────────┘
         │
         ↓
┌────────────────────────┐
│ 4. 更新事件 Annotations│
│   - 添加 ai_summary 字段│
│   - 序列化为 JSON      │
└────────┬───────────────┘
         │
         ↓
┌─────────────────┐
│  返回增强事件   │
└─────────────────┘
```

### 3.3 提示词模板系统

**模板变量**：

模板使用 Go 标准库 `text/template`，并集成 Nightingale 的自定义函数（`tplx.TemplateFuncMap`）。

可用变量：
```go
{{$event := .}}               // 完整的告警事件对象
{{$event.RuleName}}           // 告警规则名称
{{$event.Severity}}           // 严重程度 (1-3)
{{$event.TriggerValue}}       // 触发值
{{$event.TagsMap}}            // 标签映射
{{$event.AnnotationsJSON}}    // 现有注释
```

**示例模板**：

```
告警规则：{{$event.RuleName}}
严重程度：{{$event.Severity}}
触发时间：{{$event.TriggerTime}}
目标主机：{{index $event.TagsMap "host"}}
当前值：{{$event.TriggerValue}}

请分析此告警的可能原因，并提供处理建议。
```

### 3.4 AI API 调用

**请求格式**（OpenAI Chat Completion API 标准）：

```json
{
  "model": "gemini-2.0-flash",
  "messages": [
    {
      "role": "user",
      "content": "告警规则：CPU使用率过高\n严重程度：2\n..."
    }
  ],
  "temperature": 0.7,
  "max_tokens": 2000,
  "top_p": 0.9
}
```

**响应格式**：

```json
{
  "choices": [
    {
      "message": {
        "content": "该告警表明 CPU 使用率持续超过阈值..."
      }
    }
  ]
}
```

**自定义参数转换逻辑**：

`convertCustomParam()` 函数智能转换前端传入的字符串参数：

```go
// 自动识别并转换类型
"123"       → int64(123)         // 整数
"123.45"    → float64(123.45)    // 浮点数
"true"      → bool(true)         // 布尔值
"[1,2,3]"   → []interface{}      // JSON 数组
```

---

## 4. 使用方式

### 4.1 配置示例

```json
{
  "type": "ai_summary",
  "settings": {
    "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
    "model_name": "gemini-2.0-flash",
    "api_key": "your-api-key-here",
    "timeout": 30000,
    "skip_ssl_verify": false,
    "prompt_template": "告警规则：{{$event.RuleName}}\n严重程度：{{$event.Severity}}\n目标主机：{{index $event.TagsMap \"host\"}}\n\n请分析此告警并提供处理建议。",
    "custom_params": {
      "temperature": 0.7,
      "max_tokens": 2000,
      "top_p": 0.9
    }
  }
}
```

### 4.2 支持的 AI 服务

| 服务 | API 端点示例 | 模型示例 |
|------|--------------|----------|
| OpenAI | `https://api.openai.com/v1/chat/completions` | `gpt-4`, `gpt-3.5-turbo` |
| Google Gemini | `https://generativelanguage.googleapis.com/v1beta/openai/chat/completions` | `gemini-2.0-flash`, `gemini-pro` |
| Azure OpenAI | `https://{resource}.openai.azure.com/openai/deployments/{model}/chat/completions` | 自定义部署名称 |
| 本地 LLM | `http://localhost:11434/v1/chat/completions` | `llama2`, `codellama` |

### 4.3 输出示例

处理后的告警事件会在 `annotations` 字段中增加 `ai_summary` 键：

```json
{
  "rule_name": "CPU 使用率过高",
  "severity": 2,
  "tags": ["host=web-server-01"],
  "annotations": {
    "description": "CPU 使用率超过 80%",
    "ai_summary": "该告警表明 web-server-01 服务器的 CPU 使用率持续超过阈值。可能的原因包括：\n1. 应用程序负载过高\n2. 后台任务占用过多资源\n3. 潜在的死循环或性能问题\n\n建议处理步骤：\n1. 使用 top 命令查看占用 CPU 的进程\n2. 检查应用日志是否有异常\n3. 考虑水平扩容或优化代码"
  }
}
```

---

## 5. 技术亮点

### 5.1 插件化架构

- **自动注册**：通过 `init()` 函数实现零配置注册
- **接口隔离**：`Processor` 接口定义清晰，易于扩展新处理器
- **依赖注入**：配置通过 `Init()` 方法注入，支持动态配置

### 5.2 泛型优化

使用 Go 泛型简化初始化逻辑：

```go
// common/common.go
func InitProcessor[T any](settings interface{}) (T, error) {
    b, _ := json.Marshal(settings)
    var result T
    json.Unmarshal(b, &result)
    return result, nil
}
```

**优势**：
- 减少样板代码
- 类型安全
- 所有处理器共享通用逻辑

### 5.3 模板引擎集成

- 复用 Nightingale 现有的模板函数库（`tplx.TemplateFuncMap`）
- 支持丰富的模板语法（条件、循环、函数调用）
- 错误处理完善（模板解析错误、执行错误分离）

### 5.4 HTTP 客户端最佳实践

```go
// 支持 SSL 跳过、代理、超时配置
transport := &http.Transport{
    TLSClientConfig: &tls.Config{InsecureSkipVerify: c.SkipSSLVerify},
}
if c.Proxy != "" {
    proxyURL, _ := url.Parse(c.Proxy)
    transport.Proxy = http.ProxyURL(proxyURL)
}
c.Client = &http.Client{
    Timeout:   time.Duration(c.Timeout) * time.Millisecond,
    Transport: transport,
}
```

---

## 6. 测试

### 6.1 单元测试覆盖

测试文件：`ai_summary_test.go`

**测试用例**：

1. **`TestAISummaryConfig_Process`**
   - 验证完整的处理流程
   - 测试模板渲染
   - 测试 AI API 调用（真实 API）
   - 验证 annotations 更新

2. **`TestConvertCustomParam`**
   - 测试参数类型转换逻辑
   - 覆盖场景：
     - nil 值处理
     - 字符串转整数
     - 字符串转浮点数
     - 字符串转布尔值
     - JSON 数组解析
     - JSON 对象解析
     - 普通字符串保持不变

### 6.2 运行测试

```bash
cd nightingale/alert/pipeline/processor/aisummary
go test -v
```

**测试输出示例**：

```
=== RUN   TestAISummaryConfig_Process
=== 处理结果 ===
告警规则: Test Rule
严重程度: 1
标签: map[host:test-host]
原始注释: Test alert
AI总结: 该告警表明测试规则被触发，严重程度为低级别...
--- PASS: TestAISummaryConfig_Process (2.35s)
```

---

## 7. 扩展与优化

### 7.1 可能的改进方向

1. **缓存机制**
   - 对相似告警事件缓存 AI 摘要
   - 减少 API 调用成本
   - 使用 LRU 缓存避免内存溢出

2. **流式响应支持**
   - 支持 Server-Sent Events (SSE)
   - 实时显示 AI 生成进度
   - 更好的用户体验

3. **多模型策略**
   - 根据告警严重程度选择不同模型
   - 高优先级告警使用高性能模型
   - 普通告警使用经济型模型

4. **本地模型集成**
   - 集成 Ollama、LocalAI 等本地推理引擎
   - 降低延迟和成本
   - 数据隐私保护

### 7.2 配置最佳实践

**推荐配置**：

```json
{
  "type": "ai_summary",
  "settings": {
    "url": "https://your-ai-service.com/v1/chat/completions",
    "model_name": "gpt-4",
    "api_key": "${AI_API_KEY}",          // 使用环境变量
    "timeout": 15000,                     // 15 秒超时
    "skip_ssl_verify": false,             // 生产环境不跳过 SSL
    "prompt_template": "...",
    "custom_params": {
      "temperature": 0.5,                 // 降低随机性，提高一致性
      "max_tokens": 1000,                 // 控制输出长度
      "top_p": 0.9
    }
  }
}
```

**性能优化建议**：
- 合理设置 `timeout`，避免长时间阻塞告警流水线
- 使用 `max_tokens` 限制输出长度，降低成本
- 调整 `temperature` 值，平衡创造性和稳定性

---

## 8. 故障排查

### 8.1 常见问题

**问题 1：HTTP 请求超时**

```
failed to send request: context deadline exceeded
```

**解决方案**：
- 增加 `timeout` 配置值
- 检查网络连接和代理配置
- 验证 API 端点是否可达

---

**问题 2：AI 响应解析失败**

```
failed to unmarshal response: invalid character '<' looking for beginning of value
```

**解决方案**：
- 检查 API 端点是否正确（可能返回了 HTML 404 页面）
- 验证 API 密钥是否有效
- 检查模型名称是否正确

---

**问题 3：模板渲染错误**

```
failed to parse prompt template: template: prompt:1: unexpected "}"
```

**解决方案**：
- 检查模板语法是否正确
- 确保变量名拼写正确（如 `$event.RuleName` 而非 `$event.rulename`）
- 验证模板中的函数调用是否存在于 `tplx.TemplateFuncMap` 中

---

**问题 4：自定义参数未生效**

**解决方案**：
- 检查参数名是否与 API 文档一致
- 验证参数类型转换是否正确（可通过单元测试 `TestConvertCustomParam` 验证）
- 查看 AI 服务是否支持该参数

---

### 8.2 调试技巧

**启用详细日志**：

```go
// 在 generateAISummary 中添加调试日志
logger.Debugf("AI Request: %s", string(jsonData))
logger.Debugf("AI Response: %s", string(body))
```

**使用单元测试验证配置**：

```bash
# 使用真实 API 密钥运行测试
export AI_API_KEY="your-real-api-key"
go test -v -run TestAISummaryConfig_Process
```

---

## 9. 总结

AI 处理模块是 Nightingale 告警系统的智能化增强组件，通过以下特性提升了告警的可操作性：

✅ **即插即用**：通过处理器注册机制，无需修改核心代码  
✅ **灵活可配**：支持自定义提示词模板和模型参数  
✅ **标准兼容**：遵循 OpenAI API 标准，支持主流 AI 服务  
✅ **类型安全**：使用泛型和接口，减少运行时错误  
✅ **易于测试**：完善的单元测试覆盖  

该模块展示了 Nightingale 在告警处理流程中的扩展能力，为未来集成更多 AI 能力（如根因分析、异常预测）奠定了架构基础。

---

## 附录

### A. 相关文件清单

| 文件路径 | 说明 |
|----------|------|
| `nightingale/alert/pipeline/processor/aisummary/ai_summary.go` | 核心实现 |
| `nightingale/alert/pipeline/processor/aisummary/ai_summary_test.go` | 单元测试 |
| `nightingale/alert/pipeline/processor/common/common.go` | 通用初始化逻辑 |
| `nightingale/alert/pipeline/processor/callback/callback.go` | HTTP 配置基类 |
| `nightingale/models/event_processor.go` | 处理器接口定义 |
| `nightingale/models/alert_cur_event.go` | 告警事件结构体 |
| `nightingale/alert/pipeline/pipeline.go` | 处理器包导入 |

### B. 参考资源

- [OpenAI Chat Completion API 文档](https://platform.openai.com/docs/api-reference/chat)
- [Go Template 文档](https://pkg.go.dev/text/template)
- [Nightingale 官方文档](https://github.com/ccfos/nightingale)
